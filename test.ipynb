{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79445590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "def eachFile(filepath):\n",
    "\tpathDir = os.listdir(filepath)\n",
    "\tout = []\n",
    "\tfor allDir in pathDir:\n",
    "\t\tchild = allDir\n",
    "\t\tout.append(child)\n",
    "\treturn out\n",
    "\n",
    "\n",
    "NUM_CLASSES = 11\n",
    "TRAIN_PATH = 'dataset/train/'\n",
    "TEST_PATH = 'dataset/test/'\n",
    "\n",
    "FC_NUMS = 4096\n",
    "\n",
    "FREEZE_LAYERS = 17\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "base_model = VGG19(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "prediction = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=prediction)\n",
    "\n",
    "for layer in model.layers[:FREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[FREEZE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=gradient_descent_v2.SGD(learning_rate=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(directory=TRAIN_PATH,\n",
    "                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE), classes=eachFile(TRAIN_PATH))\n",
    "filepath = 'model/sewer_weight.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history_ft = model.fit_generator(train_generator, epochs=10, callbacks=[checkpoint])\n",
    "model.save('model/sewer_weight_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e092fbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x17f588860>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/test.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/test.ipynb#ch0000001?line=25'>26</a>\u001b[0m images \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/test.ipynb#ch0000001?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(folder_path):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/test.ipynb#ch0000001?line=27'>28</a>\u001b[0m    img1 \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mload_img(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(folder_path, img), target_size\u001b[39m=\u001b[39;49m(img_width, img_height))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/test.ipynb#ch0000001?line=28'>29</a>\u001b[0m    img2 \u001b[39m=\u001b[39m img_to_array(img1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/test.ipynb#ch0000001?line=29'>30</a>\u001b[0m    img2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(img2, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py:292\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(path, grayscale\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, color_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrgb\u001b[39m\u001b[39m'\u001b[39m, target_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=258'>259</a>\u001b[0m              interpolation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnearest\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=259'>260</a>\u001b[0m   \u001b[39m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=260'>261</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=261'>262</a>\u001b[0m \u001b[39m  Usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=289'>290</a>\u001b[0m \u001b[39m      ValueError: if interpolation method is not supported.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=290'>291</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=291'>292</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m image\u001b[39m.\u001b[39;49mload_img(path, grayscale\u001b[39m=\u001b[39;49mgrayscale, color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/preprocessing/image.py?line=292'>293</a>\u001b[0m                         target_size\u001b[39m=\u001b[39;49mtarget_size, interpolation\u001b[39m=\u001b[39;49minterpolation)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:114\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=110'>111</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not import PIL.Image. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=111'>112</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mThe use of `load_img` requires PIL.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=112'>113</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=113'>114</a>\u001b[0m     img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39;49mopen(io\u001b[39m.\u001b[39;49mBytesIO(f\u001b[39m.\u001b[39;49mread()))\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=114'>115</a>\u001b[0m     \u001b[39mif\u001b[39;00m color_mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=115'>116</a>\u001b[0m         \u001b[39m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=116'>117</a>\u001b[0m         \u001b[39m# convert it to an 8-bit grayscale image.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras_preprocessing/image/utils.py?line=117'>118</a>\u001b[0m         \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mmode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mL\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mI\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/PIL/Image.py:3123\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/PIL/Image.py?line=3120'>3121</a>\u001b[0m \u001b[39mfor\u001b[39;00m message \u001b[39min\u001b[39;00m accept_warnings:\n\u001b[1;32m   <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/PIL/Image.py?line=3121'>3122</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message)\n\u001b[0;32m-> <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/PIL/Image.py?line=3122'>3123</a>\u001b[0m \u001b[39mraise\u001b[39;00m UnidentifiedImageError(\n\u001b[1;32m   <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/PIL/Image.py?line=3123'>3124</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcannot identify image file \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (filename \u001b[39mif\u001b[39;00m filename \u001b[39melse\u001b[39;00m fp)\n\u001b[1;32m   <a href='file:///Users/iyunji/miniforge3/envs/tensorflow/lib/python3.9/site-packages/PIL/Image.py?line=3124'>3125</a>\u001b[0m )\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x17f588860>"
     ]
    }
   ],
   "source": [
    "\n",
    "   \n",
    "from tensorflow.python.keras.initializers import glorot_uniform\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.preprocessing.image import  img_to_array\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "# image folder\n",
    "folder_path = 'dataset/test/'\n",
    "\n",
    "# path to model\n",
    "model_path = 'model/sewer_weight.h5'\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model(model_path)\n",
    "\n",
    "# dimensions of images\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "\n",
    "i = 0\n",
    "images = []\n",
    "for img in os.listdir(folder_path):\n",
    "   img1 = image.load_img(os.path.join(folder_path, img), target_size=(img_width, img_height))\n",
    "   img2 = img_to_array(img1)\n",
    "   img2 = np.expand_dims(img2, axis=0)\n",
    "   classes = model.predict(img2)[0]\n",
    "   idxs = np.argsort(classes)[::-1][:1]\n",
    "\n",
    "   classname = ['UD_IN', 'UD_PJ', 'JF', 'BK', 'JD', 'SD', 'DS', 'ETC',\n",
    "                'CC', 'CL', 'LP']\n",
    "\n",
    "   out = cv2.imread(os.path.join(folder_path, img))\n",
    "\n",
    "   for (i, j) in enumerate(idxs):\n",
    "       label = \"{}:{:.2f}%\".format(classname[idxs[i]], classes[idxs[i]] * 100)\n",
    "       cv2.putText(out, label, (10, (i * 30) + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "   cv2.imwrite(\"visualization/sd/%s\"%img,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "bad_list=[]\n",
    "dir=r'dataset/train/'\n",
    "subdir_list=os.listdir(dir) # create a list of the sub directories in the directory ie train or test\n",
    "for d in subdir_list:  # iterate through the sub directories train and test\n",
    "    dpath=os.path.join (dir, d) # create path to sub directory\n",
    "    if d in ['test', 'train']:\n",
    "        class_list=os.listdir(dpath) # list of classes ie dog or cat\n",
    "       # print (class_list)\n",
    "        for klass in class_list: # iterate through the two classes\n",
    "            class_path=os.path.join(dpath, klass) # path to class directory\n",
    "            #print(class_path)\n",
    "            file_list=os.listdir(class_path) # create list of files in class directory\n",
    "            for f in file_list: # iterate through the files\n",
    "                fpath=os.path.join (class_path,f)\n",
    "                index=f.rfind('.') # find index of period infilename\n",
    "                ext=f[index+1:] # get the files extension\n",
    "                if ext  not in ['jpg', 'png', 'bmp', 'gif']:\n",
    "                    print(f'file {fpath}  has an invalid extension {ext}')\n",
    "                    bad_list.append(fpath)                    \n",
    "                else:\n",
    "                    try:\n",
    "                        img=cv2.imread(fpath)\n",
    "                        size=img.shape\n",
    "                    except:\n",
    "                        print(f'file {fpath} is not a valid image file ')\n",
    "                        bad_list.append(fpath)\n",
    "                       \n",
    "print (bad_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7625ba19274300b60e416e1653561b01d82a278577aa3faa59ceacf488eb03f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
