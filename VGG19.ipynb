{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras import layers, models\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import adam_v2\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5\"\n",
    "\n",
    "def eachFile(filepath):\n",
    "\tpathDir = os.listdir(filepath)\n",
    "\tout = []\n",
    "\tfor allDir in pathDir:\n",
    "\t\tchild = allDir\n",
    "\t\tout.append(child)\n",
    "\treturn out\n",
    "\n",
    "\n",
    "NUM_CLASSES = 11\n",
    "TRAIN_PATH = '/Volumes/T7/CCTV_data/Training'\n",
    "#TRAIN_PATH = '/Volumes/T7/validation/Validation'\n",
    "VALID_PATH = 'dataset/train'\n",
    "FC_NUMS = 4096\n",
    "\n",
    "FREEZE_LAYERS = 17\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "base_model = VGG19(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(base_model)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4096, activation='relu'))\n",
    "additional_model.add(layers.Dense(2048, activation='relu'))\n",
    "additional_model.add(layers.Dense(1024, activation='relu'))\n",
    "additional_model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "additional_model.summary()\n",
    "\n",
    "additional_model.compile(optimizer=adam_v2.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "train_datagen = ImageDataGenerator(    \n",
    "    rescale = 1. /255.,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(directory=TRAIN_PATH,\n",
    "                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE), classes=eachFile(TRAIN_PATH), subset='training')\n",
    "test_generator = train_datagen.flow_from_directory(directory=TRAIN_PATH,\n",
    "                                                    target_size=(IMAGE_SIZE, IMAGE_SIZE), classes=eachFile(TRAIN_PATH), subset='validation')\n",
    "print(test_generator.class_indices)\n",
    "filepath = 'model/sewer_weight.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history_ft = additional_model.fit_generator(train_generator, epochs=20, callbacks=[checkpoint], \n",
    "                                 validation_data=test_generator, validation_steps=5)\n",
    "additional_model.save('model/sewer_weight_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.python.keras.initializers import glorot_uniform\n",
    "from keras.layers import GlobalAveragePooling2D, Dense \n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\"\n",
    "\n",
    "print(\"-- Evaluate --\")\n",
    "#valid_dir = '/Volumes/T7/validation/Validation'\n",
    "#valid_dir = 'dataset/Testing'\n",
    "#valid_dir = '/Volumes/T7/CCTV_data/Testing'\n",
    "valid_dir = 'dataset/sd'\n",
    "model_path = 'model_test/sewer_weight.h5'\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model(model_path)\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "def eachFile(filepath):\n",
    "     pathDir = os.listdir(filepath)\n",
    "     out = []\n",
    "     for allDir in pathDir:\n",
    "             child = allDir\n",
    "             out.append(child)\n",
    "     return out\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "# 'valid_dir' 디렉토리에 저장된 이미지 전처리\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), class_mode='categorical',shuffle=False)\n",
    "print(valid_generator.class_indices)\n",
    "scores = model.evaluate_generator(valid_generator)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_dir = 'dataset/sd'\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "model_path = 'model_test/sewer_weight.h5'\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model(model_path)\n",
    "\n",
    "# 'valid_dir' 디렉토리에 저장된 이미지 전처리\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=False)\n",
    "test_generator.reset()\n",
    "output = model.predict(test_generator)\n",
    "\n",
    "test_file_names=test_generator.filenames  \n",
    "test_labels=test_generator.labels \n",
    "class_dict= test_generator.class_indices\n",
    "print (class_dict) \n",
    "new_dict={} \n",
    "for key in class_dict: \n",
    "    value=class_dict[key]\n",
    "    new_dict[value]=key\n",
    "print('PREDICTED CLASS      TRUE CLASS          FILENAME ' )\n",
    "for i, p in enumerate(output):\n",
    "    pred_index=np.argmax(p)\n",
    "    pred_class=new_dict[pred_index] \n",
    "    true_class=new_dict[test_labels[i]]\n",
    "    file=test_file_names[i]\n",
    "    print(f'       {pred_class}           {true_class}            {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-27 20:53:05.839937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  8  5  5  8  3  3  8  5  8  8  8  8  8  1  8  7  7  2  7  8  0  0  8\n",
      "  1  8  8  8  7  8  8  8  8  7  8  9  9  9  9  9  9 10 10  8  5  5  5  1\n",
      "  8  1  0  5  5  5  5  5  5  8  4  4  4  4  4  9  9  9  9  9  9  2  8  8\n",
      "  8  7  5]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=24'>25</a>\u001b[0m labels \u001b[39m=\u001b[39m (test_generator\u001b[39m.\u001b[39mclass_indices)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=25'>26</a>\u001b[0m labelss \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((v,k) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m labels\u001b[39m.\u001b[39mitems())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=26'>27</a>\u001b[0m predictions \u001b[39m=\u001b[39m [labelss[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m predicted_class_indices]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=28'>29</a>\u001b[0m filenames\u001b[39m=\u001b[39mtest_generator\u001b[39m.\u001b[39mfilenames\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=29'>30</a>\u001b[0m results\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m\"\u001b[39m:filenames,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=30'>31</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m\"\u001b[39m:predictions})\n",
      "\u001b[1;32m/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb Cell 4'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=24'>25</a>\u001b[0m labels \u001b[39m=\u001b[39m (test_generator\u001b[39m.\u001b[39mclass_indices)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=25'>26</a>\u001b[0m labelss \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m((v,k) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m labels\u001b[39m.\u001b[39mitems())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=26'>27</a>\u001b[0m predictions \u001b[39m=\u001b[39m [labelss[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m predicted_class_indices]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=28'>29</a>\u001b[0m filenames\u001b[39m=\u001b[39mtest_generator\u001b[39m.\u001b[39mfilenames\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=29'>30</a>\u001b[0m results\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame({\u001b[39m\"\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m\"\u001b[39m:filenames,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/iyunji/Documents/workspace_vscode/capstone/capstone_AI/VGG19.ipynb#ch0000003?line=30'>31</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m\"\u001b[39m:predictions})\n",
      "\u001b[0;31mKeyError\u001b[0m: 8"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.python.keras.initializers import glorot_uniform\n",
    "from keras.layers import GlobalAveragePooling2D, Dense \n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "test_dir = 'dataset/sd_new'\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "model_path = 'model_test_new/sewer_weight.h5'\n",
    "with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model(model_path)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=False, class_mode = 'categorical')\n",
    "test_generator.reset()\n",
    "scores=model.predict_generator(test_generator, len(test_generator))\n",
    "\n",
    "predicted_class_indices=np.argmax(scores,axis=1)\n",
    "print(predicted_class_indices)\n",
    "\n",
    "labels = (test_generator.class_indices)\n",
    "labelss = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labelss[k] for k in predicted_class_indices]\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "#folder_path = '/Volumes/T7/CCTV_data/Training/DS'\n",
    "#folder_path = 'dataset/train/'\n",
    "\n",
    "folder_path = '/Volumes/T7/validation/Validation/UD_PJ'\n",
    "print(len(os.listdir(folder_path)))\n",
    "path = Path(folder_path).rglob(\"*.png\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "            print(img_p)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7625ba19274300b60e416e1653561b01d82a278577aa3faa59ceacf488eb03f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
